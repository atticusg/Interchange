{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrated Gradients calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.mqnli import get_collate_fxn\n",
    "from modeling.pretrained_bert import PretrainedBertModule\n",
    "from modeling.lstm import LSTMModule\n",
    "import os\n",
    "from trainer import load_model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from feature_importance import IntegratedGradientsBERT, IntegratedGradientsLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ig_load_model(src_basename, src_dirname=\"mqnli_models\"):\n",
    "    path = os.path.join(src_dirname, src_basename)\n",
    "    if 'lstm' in src_basename:\n",
    "        model_class = LSTMModule\n",
    "    else:\n",
    "        model_class = PretrainedBertModule\n",
    "\n",
    "    model, _ = load_model(model_class, path, device=device)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_easy = ig_load_model(\"bert-easy-best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_hard = ig_load_model(\"bert-hard-best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lstm_model_easy = ig_load_model(\"lstm-easy-best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lstm_model_hard = ig_load_model(\"lstm-hard-best.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ig_load_dev(src_basename, src_dirname=\"mqnli_models\"):\n",
    "    path = os.path.join(src_dirname, src_basename)\n",
    "    data = torch.load(path)\n",
    "    return data.dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_dev = ig_load_dev(\"bert-preprocessed-data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lstm_dev = ig_load_dev(\"lstm-preprocessed-data.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sample(model, examples, n=8, batch_size=4, output_filename=None, layer=None, shuffle=True):\n",
    "    n_batches = int(n / batch_size)\n",
    "    if 'LSTM' in model.__class__.__name__:\n",
    "        ig_class = IntegratedGradientsLSTM\n",
    "        collate_fn = get_collate_fxn(examples, batch_first=False)\n",
    "    else:\n",
    "        ig_class = IntegratedGradientsBERT\n",
    "        collate_fn = None\n",
    "    ig = ig_class(model, layer=layer)\n",
    "    dataloader = DataLoader(examples, batch_size=batch_size, shuffle=shuffle, collate_fn=collate_fn)\n",
    "    data = []\n",
    "    with torch.no_grad():\n",
    "        for i, input_tuple in enumerate(dataloader, start=1):\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Batch {i} of {n_batches}\")\n",
    "            input_tuple = tuple([x.to(device) for x in input_tuple])\n",
    "            data += ig.predict_with_ig(input_tuple)\n",
    "            if i == n_batches:\n",
    "                break\n",
    "    if output_filename:\n",
    "        ig.to_json(data, output_filename)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_data_emb = analyze_sample(\n",
    "    bert_model_easy,\n",
    "    bert_dev, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IntegratedGradientsBERT.visualize(bert_data_emb[: 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_data_enc0 = analyze_sample(\n",
    "    bert_model_easy,\n",
    "    bert_dev,\n",
    "    shuffle=False,\n",
    "    layer=bert_model_easy.bert.encoder.layer[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IntegratedGradientsBERT.visualize(bert_data_enc0[: 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_data_enc11 = analyze_sample(\n",
    "    bert_model_easy,\n",
    "    bert_dev,\n",
    "    shuffle=False,\n",
    "    layer=bert_model_easy.bert.encoder.layer[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IntegratedGradientsBERT.visualize(bert_data_enc11[: 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm_data_emb = analyze_sample(\n",
    "#     lstm_model_easy,\n",
    "#     lstm_dev,\n",
    "#     shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_data_easy = analyze_sample(\n",
    "    bert_model_easy,\n",
    "    bert_dev,\n",
    "    n=10000,\n",
    "    layer=bert_model_easy.bert.embeddings,\n",
    "    output_filename='../ig-bert-easy-emb-10k.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_data_hard = analyze_sample(\n",
    "    bert_model_hard,\n",
    "    bert_dev,\n",
    "    n=10000,\n",
    "    layer=bert_model_hard.bert.embeddings,\n",
    "    output_filename='../ig-bert-hard-emb-10k.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_data_easy = analyze_sample(\n",
    "    bert_model_easy,\n",
    "    bert_dev,\n",
    "    n=10000,\n",
    "    layer=bert_model_easy.bert.encoder.layer[11],\n",
    "    output_filename='../ig-bert-easy-layer11-10k.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_data_hard = analyze_sample(\n",
    "    bert_model_hard,\n",
    "    bert_dev,\n",
    "    n=10000,\n",
    "    layer=bert_model_hard.bert.encoder.layer[11],\n",
    "    output_filename='../ig-bert-hard-layer11-10k.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
